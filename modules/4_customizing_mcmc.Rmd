---
title: "Customizing an MCMC"
subtitle: "enviBayes 2021 tutorial"
author: "NIMBLE Development Team"
output:
  html_document:
    code_folding: show
---

```{r chunksetup, include=FALSE} 
# include any code here you don't want to show up in the document,
# e.g. package and dataset loading
library(methods)  # otherwise new() not being found - weird
library(nimble)
library(coda)
source("chunks_litters.R")
```

# Customizing samplers: examining the defaults

One of NIMBLE's most important features is that users can easily modify the MCMC algorithm used for their model. The easiest thing to do is to start with NIMBLE's default MCMC and then make modifications. 

```{r default-config}
littersConf$printSamplers()
```

# Customizing samplers: modifying the samplers

Let's try using slice samplers (these are used by default much more heavily in JAGS than in NIMBLE).

```{r customize-mcmc}
hypers <- c('a[1]', 'b[1]', 'a[2]', 'b[2]')
for(h in hypers) {
      littersConf$removeSamplers(h)
      littersConf$addSampler(target = h, type = 'slice')
}
littersConf$printSamplers()

littersMCMC <- buildMCMC(littersConf)
## We need 'resetFunctions' because we are rebuilding the MCMC for an existing model for
## which we've already done some compilation.
cLittersMCMC <- compileNimble(littersMCMC, project = littersModel,
   resetFunctions = TRUE)

niter <- 1000
nburn <- 100

set.seed(1)
samplesSlice <- runMCMC(cLittersMCMC, niter = niter, nburnin = nburn,
             inits = littersInits, nchains = 1, samplesAsCodaMCMC = TRUE)
```

# Customizing samplers: Initial results

We can look at diagnostics and see if the change in samplers had an effect. Here, simply changing the univariate samplers doesn't have much effect, because the real story is in the posterior correlation between ```a[i]``` and ```b[i]```. But in other cases it can make a bigger difference.

Caveat: the real question is the effective sample size per unit of computation time (each slice sampler iteration is much slower than each Metropolis iteration), but we don't assess that at the moment.


```{r output-slice, fig.height=6, fig.width=12, fig.cap=''}
effectiveSize(samplesSlice)
makePlot(samplesSlice)
```

# Blocking parameters

Often a key factor that reduces MCMC performance is dependence between parameters that limits the ability of univariate samplers to move very far. A standard strategy is to sample correlated parameters in blocks. Unlike many other MCMC engines, NIMBLE makes it easy for users to choose what parameters to sample in blocks.

We'll try that here for ```a``` and ```b```.

```{r customize-mcmc2}
niter <- 5000
nburn <- 1000

littersConf <- configureMCMC(littersModel, monitors = c('a', 'b', 'p'))
hypers <- littersModel$getNodeNames(topOnly = TRUE)
print(hypers)
for(h in hypers) {
      littersConf$removeSamplers(h)
}
littersConf$addSampler(target = c('a[1]','b[1]'), type = 'RW_block', 
                              control = list(adaptInterval = 20, adaptFactorExponent = 0.25))
littersConf$addSampler(target = c('a[2]','b[2]'), type = 'RW_block', 
                              control = list(adaptInterval = 20, adaptFactorExponent = 0.25))


littersMCMC <- buildMCMC(littersConf)
cLittersMCMC <- compileNimble(littersMCMC, project = littersModel, resetFunctions = TRUE)

set.seed(1)
samplesBlock <- runMCMC(cLittersMCMC, niter = niter, nburnin = nburn,
             inits = littersInits, nchains = 1, samplesAsCodaMCMC = TRUE)
```

```{r output-block, fig.height=6, fig.width=12, fig.cap=''}
effectiveSize(samplesBlock)
makePlot(samplesBlock)
```

The block sampler seems to help some, but hopefully we can do better. Often block sampling gives bigger improvements.

